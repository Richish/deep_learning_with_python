{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch64_convnets_for_sequence_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYqE5SrEAgWLmv4cx9gndT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Richish/deep_learning_with_python/blob/master/ch64_convnets_for_sequence_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxTAEkex_1Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDikcBFOAI5R",
        "colab_type": "text"
      },
      "source": [
        "# Preparing imdb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfZKDQyiAM5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07f3fd78-c5c2-4220-d5a1-ce8b77db1e4b"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vwjyCVqAND8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "afa92e76-ac8f-4b55-f2ac-f9eebf85744a"
      },
      "source": [
        "max_features=10_000\n",
        "max_len=500\n",
        "\n",
        "(x_train, y_train), (x_test, y_test)=imdb.load_data(num_words=max_features)\n",
        "print(x_train.shape, x_test.shape)\n",
        "print(\"Pad seqiuences\")\n",
        "\n",
        "x_train=sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test=sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n",
            "(25000,) (25000,)\n",
            "Pad seqiuences\n",
            "(25000, 500) (25000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fijZm2DeANGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MUmSnT8CFSB",
        "colab_type": "text"
      },
      "source": [
        "# Train and evaluate simple 1d convent on imdb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD-Qv6CNANJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, GlobalMaxPool1D\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bWPfgR8ANMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e815d5b0-61dd-4a6b-f46b-8c1dbf82360b"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=max_len))\n",
        "model.add(Conv1D(filters=32, kernel_size=7, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=5))\n",
        "model.add(Conv1D(filters=32, kernel_size=7, activation='relu'))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,315,937\n",
            "Trainable params: 1,315,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JAO5o3XANPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBAJXMgYANa1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "ef0256db-9326-4b78-a573-06829a5a4601"
      },
      "source": [
        "history=model.fit(x=x_train, y=y_train, batch_size=128, epochs=10, validation_split=0.2, use_multiprocessing=True, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 9s 444us/step - loss: 0.6927 - acc: 0.5218 - val_loss: 0.6919 - val_acc: 0.5324\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 2s 117us/step - loss: 0.6868 - acc: 0.6716 - val_loss: 0.6882 - val_acc: 0.6438\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 2s 117us/step - loss: 0.6771 - acc: 0.7540 - val_loss: 0.6755 - val_acc: 0.7242\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 2s 117us/step - loss: 0.6480 - acc: 0.7919 - val_loss: 0.6226 - val_acc: 0.7826\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 2s 117us/step - loss: 0.5611 - acc: 0.8164 - val_loss: 0.5052 - val_acc: 0.8218\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 2s 117us/step - loss: 0.4347 - acc: 0.8473 - val_loss: 0.4000 - val_acc: 0.8424\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 2s 116us/step - loss: 0.3456 - acc: 0.8690 - val_loss: 0.3491 - val_acc: 0.8550\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 2s 116us/step - loss: 0.2941 - acc: 0.8863 - val_loss: 0.3249 - val_acc: 0.8632\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 2s 117us/step - loss: 0.2614 - acc: 0.8993 - val_loss: 0.3140 - val_acc: 0.8680\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 2s 119us/step - loss: 0.2374 - acc: 0.9088 - val_loss: 0.3081 - val_acc: 0.8686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgspu5e3ANd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP4Sv0gnHGsm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Combination of CNN and RNN on temperature forecasting problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgIfjzCdANgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a3c4c2f2-0b30-45a7-b288-3ed4a4ff22e9"
      },
      "source": [
        "!ls\n",
        "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
        "!unzip jena_climate_2009_2016.csv.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "--2020-05-23 01:21:25--  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.226.251\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.226.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13568290 (13M) [application/zip]\n",
            "Saving to: ‘jena_climate_2009_2016.csv.zip’\n",
            "\n",
            "jena_climate_2009_2 100%[===================>]  12.94M  5.52MB/s    in 2.3s    \n",
            "\n",
            "2020-05-23 01:21:29 (5.52 MB/s) - ‘jena_climate_2009_2016.csv.zip’ saved [13568290/13568290]\n",
            "\n",
            "Archive:  jena_climate_2009_2016.csv.zip\n",
            "  inflating: jena_climate_2009_2016.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FCWKhh4Hwge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a51fbd9d-fa16-4e6e-8edf-cfc89f076e95"
      },
      "source": [
        "data_file=\"jena_climate_2009_2016.csv\"\n",
        "\n",
        "df=pd.read_csv(data_file)\n",
        "\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 420551 entries, 0 to 420550\n",
            "Data columns (total 15 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   Date Time        420551 non-null  object \n",
            " 1   p (mbar)         420551 non-null  float64\n",
            " 2   T (degC)         420551 non-null  float64\n",
            " 3   Tpot (K)         420551 non-null  float64\n",
            " 4   Tdew (degC)      420551 non-null  float64\n",
            " 5   rh (%)           420551 non-null  float64\n",
            " 6   VPmax (mbar)     420551 non-null  float64\n",
            " 7   VPact (mbar)     420551 non-null  float64\n",
            " 8   VPdef (mbar)     420551 non-null  float64\n",
            " 9   sh (g/kg)        420551 non-null  float64\n",
            " 10  H2OC (mmol/mol)  420551 non-null  float64\n",
            " 11  rho (g/m**3)     420551 non-null  float64\n",
            " 12  wv (m/s)         420551 non-null  float64\n",
            " 13  max. wv (m/s)    420551 non-null  float64\n",
            " 14  wd (deg)         420551 non-null  float64\n",
            "dtypes: float64(14), object(1)\n",
            "memory usage: 48.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fzt6vOhIRId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.drop(columns='Date Time')\n",
        "df.keys()\n",
        "\n",
        "mean=df.loc[:200_000].mean()\n",
        "std=df.loc[:200_000].std()\n",
        "df-=mean\n",
        "df/=std\n",
        "df.head()\n",
        "\n",
        "float_data=df.to_numpy()\n",
        "float_data.shape\n",
        "\n",
        "def generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
        "    \"\"\"\n",
        "    data: np.array > of full data set.\n",
        "    lookback: no. of datapoints to look back in each sample.\n",
        "    delay: no. of datapoints after current sample for which prediction is to be made, or which corresponds to y\n",
        "    min_index: consider datapoints starting from this index only\n",
        "    max_index: Take datapoint upto max this index only\n",
        "    shuffle: shuffle the data before taking a batch out of data and yielding that\n",
        "    batch_size: no. of samples to be yielded in a single batch\n",
        "    step: not all data points will be considered, only datapoints at frequency- 'step' will be considered. \n",
        "            since data points aare at 10 min interval so step=6 implies only hourly data will be considered.\n",
        "    return: a tuple of (samples, data_samples_at_delay). Samples is a 2d np array of shape: (batch_size, lookback, data.shape[-1]). Basically a a batch of samples, \n",
        "            where each sample contains a np array of shape(lookback, data.shape[-1])\n",
        "            data_samples_at_delay is a 2d np array of shape: (batch_size, 1)- 1 since we only need temperature as output\n",
        "    \"\"\"\n",
        "    if max_index is None:\n",
        "        max_index = len(data) - delay - 1\n",
        "    i = min_index + lookback # which rows that will contain the end of sample data, delay will be relative to this row.\n",
        "    while True:\n",
        "        if shuffle:\n",
        "            # rows will be equal to batch_size\n",
        "            rows=np.random.randint(i, max_index, size=batch_size) # basically row indexes.\n",
        "        else: # not shuffled\n",
        "            if i+batch_size>max_index: # if reached end, need to rotate and go to beginning to get new batch\n",
        "                i=min_index+lookback\n",
        "            rows=np.arange(i, min(i+batch_size,max_index))\n",
        "            i+=len(rows) # move pointer to where end of next batch would be\n",
        "        # initializing samples and targets to 0s.\n",
        "        samples=np.zeros((len(rows), lookback//step, data.shape[-1]))\n",
        "        targets=np.zeros((len(rows),))\n",
        "        # setting the value of samples and targets for each sample/target in a batch of batch_size\n",
        "        for j, row in enumerate(rows):\n",
        "            indeces=np.arange(row-lookback, row, step)\n",
        "            samples[j]=data[indeces]\n",
        "            targets[j]=data[row+delay][1] # we only need the temperature as output/label\n",
        "        yield samples, targets\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ME0EZxxI4Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lookback = 24*5*6 # 5 days data\n",
        "step = 6\n",
        "delay = 24*6 # 1 day's delay/prediction\n",
        "batch_size = 128 # training batch size\n",
        "\n",
        "train_gen = generator(float_data,\n",
        "                lookback=lookback,\n",
        "                delay=delay,\n",
        "                min_index=0,\n",
        "                max_index=200_000,\n",
        "                shuffle=True,\n",
        "                step=step,\n",
        "                batch_size=batch_size)\n",
        "\n",
        "val_gen = generator(float_data,\n",
        "                lookback=lookback,\n",
        "                delay=delay,\n",
        "                min_index=200_001,\n",
        "                max_index=300_000,\n",
        "                shuffle=True,\n",
        "                step=step,\n",
        "                batch_size=batch_size)\n",
        "\n",
        "test_gen = generator(float_data,\n",
        "                lookback=lookback,\n",
        "                delay=delay,\n",
        "                min_index=300_001,\n",
        "                max_index=None,\n",
        "                shuffle=True,\n",
        "                step=step,\n",
        "                batch_size=batch_size)\n",
        "val_steps = (300000 - 200001 - lookback)//128 # how many val steps to look at whole data\n",
        "test_steps = (len(float_data) - 300001 - lookback)//128 # how many test steps to look at whole data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuEuUxCBHSoT",
        "colab_type": "text"
      },
      "source": [
        "## Simple 1d convndet on temp forecasting\n",
        "\n",
        "will not work well since convnets do not have a very good order-sesitivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LokokL1oANjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simple 1d convnet for temp forecasting\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPool1D, Dense\n",
        "from keras.optmimizers import RMSprop\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izAL-_o2ANl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fe45e3be-b5a4-4b91-e107-f7512a50ffed"
      },
      "source": [
        "model=Sequential()\n",
        "# model.add(Embedding()) embedding not used for timeseries forecasting. Used only for nlp or other sequences where dimensionality of data needs to be changed.\n",
        "model.add(Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(None, float_data.shape[-1])))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(units=1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, None, 32)          2272      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, None, 32)          5152      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, None, 32)          5152      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 12,609\n",
            "Trainable params: 12,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeCYL259ANo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "303d1843-7c22-4ed0-f59b-4445a631af07"
      },
      "source": [
        "model.compile(optimizer=RMSprop(learning_rate=1e-4), loss='mae')\n",
        "history=model.fit_generator(generator=train_gen, steps_per_epoch=500, epochs=20, validation_data=val_gen, validation_steps=val_steps/1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.2632 - val_loss: 0.4040\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2602 - val_loss: 0.4161\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2576 - val_loss: 0.4273\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2561 - val_loss: 0.3994\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2547 - val_loss: 0.3424\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2536 - val_loss: 0.4532\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2499 - val_loss: 0.4343\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2470 - val_loss: 0.4038\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2447 - val_loss: 0.3958\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2436 - val_loss: 0.4070\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2426 - val_loss: 0.4170\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2408 - val_loss: 0.4297\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2394 - val_loss: 0.3725\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2382 - val_loss: 0.4181\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2367 - val_loss: 0.4003\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2346 - val_loss: 0.4031\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2355 - val_loss: 0.3663\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2322 - val_loss: 0.4258\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2310 - val_loss: 0.4412\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.2301 - val_loss: 0.4322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sacT7hOfANsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STTwHM25NEJd",
        "colab_type": "text"
      },
      "source": [
        "## Combination of cnn and rnn on tmp data\n",
        "Use cnn as pre-processing layer to shorten the sequences fed into rnn hence speeding up the rnn training.\n",
        "\n",
        "Can vary cnn params to adjust the lookback time window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrhhazOMANZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this example uses a higher resolution data(sampled at 3o mins instead of 1 hour) and hence is processing a longer timeseries\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw-UkLDSN6yW",
        "colab_type": "text"
      },
      "source": [
        "### preparing high resolution data generators for jena data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J7-EtQpANXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step = 3 # this is the only thing that changed\n",
        "lookback = 720\n",
        "delay = 144\n",
        "train_gen = generator(float_data,\n",
        "                          lookback=lookback,\n",
        "                          delay=delay,\n",
        "                          min_index=0,\n",
        "                          max_index=200000,\n",
        "                          shuffle=True,\n",
        "                          step=step)\n",
        "val_gen = generator(float_data,\n",
        "                      lookback=lookback,\n",
        "                      delay=delay,\n",
        "                      min_index=200001,\n",
        "                      max_index=300000,\n",
        "                      step=step)\n",
        "test_gen = generator(float_data,\n",
        "                        lookback=lookback,\n",
        "                        delay=delay,\n",
        "                        min_index=300001,\n",
        "                        max_index=None,\n",
        "                        step=step)\n",
        "val_steps = (300000 - 200001 - lookback) // 128\n",
        "test_steps = (len(float_data) - 300001 - lookback) // 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk37UhMyANTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "3464e3a6-4dd5-4d80-aaf8-1c660d29c03b"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import RMSprop\n",
        "model = Sequential()\n",
        "model.add(layers.Conv1D(32, 5, activation='relu',input_shape=(None, float_data.shape[-1])))\n",
        "model.add(layers.MaxPooling1D(3))\n",
        "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
        "model.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5))\n",
        "model.add(layers.Dense(1))\n",
        "model.summary()\n",
        "model.compile(optimizer=RMSprop(), loss='mae')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_7 (Conv1D)            (None, None, 32)          2272      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, None, 32)          5152      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 32)                6240      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,697\n",
            "Trainable params: 13,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yP6oVPkO5Kg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "62239f47-f683-4e3e-8b08-0fd918bda952"
      },
      "source": [
        "history = model.fit_generator(train_gen,\n",
        "                                steps_per_epoch=500,\n",
        "                                epochs=20,\n",
        "                                validation_data=val_gen,\n",
        "                                validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 115s 231ms/step - loss: 907724271.1197 - val_loss: 0.2699\n",
            "Epoch 2/20\n",
            "100/500 [=====>........................] - ETA: 1:21 - loss: 122119411030.1449"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHaD5RHCO5N9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CNN and RNN is faster than RNN alone but IT IS NOT AS GOOD AS RNN IN TERMS OF ACCURACY.\n",
        "Hence can only be used where accuracy can be compromised for speed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuFrgvUaO5Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90jP3bIhO5Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyWTftWHO5x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNCC3HTWO5Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of9oIj7ZO5Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}