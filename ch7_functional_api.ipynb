{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch7_functional_api.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Richish/deep_learning_with_python/blob/master/ch7_functional_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ifecJ60SSc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AgQ0hR2Z4vx",
        "colab_type": "text"
      },
      "source": [
        "# How to make use of functional api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWdnPKq0TmnN",
        "colab_type": "text"
      },
      "source": [
        "In the functional API, you directly manipulate tensors, and you use layers as functions\n",
        "that take tensors and return tensors (hence, the name functional API):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkHeNLm6Tp37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c51bfc67-9f0f-46d0-dd59-bab2ae4f0a1e"
      },
      "source": [
        "# how does it look like\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "input_tensor=Input(shape=(64,))\n",
        "\n",
        "layer1=Dense(units=32, activation=\"relu\")\n",
        "layer2=Dense(units=32, activation=\"relu\")\n",
        "layer3=Dense(units=10, activation=\"softmax\")\n",
        "\n",
        "x=layer1(input_tensor) # x is o/p tensor for this layer\n",
        "x=layer2(x)\n",
        "output_tensor=layer3(x)\n",
        "\n",
        "model=Model(input_tensor, output_tensor)\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMN21VA8dUWe",
        "colab_type": "text"
      },
      "source": [
        "When it comes to compiling, training, or evaluating such an instance of Model, the\n",
        "API is the same as that of Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeX6jTXyTp7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "586ba8b0-46a7-486a-9048-c0528e29001a"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 64))\n",
        "y_train = np.random.random((1000, 10))\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
        "score = model.evaluate(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 12.3253\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 22us/step - loss: 13.9266\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 22us/step - loss: 16.3876\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 21us/step - loss: 19.2364\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 21us/step - loss: 22.5148\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 25us/step - loss: 26.3748\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 21us/step - loss: 30.4656\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 20us/step - loss: 35.0756\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 20us/step - loss: 40.2356\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 21us/step - loss: 45.8362\n",
            "1000/1000 [==============================] - 0s 55us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCbWVA_TqDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multi Input Models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JpoCnCNdzmv",
        "colab_type": "text"
      },
      "source": [
        "# Multi Input Models\n",
        "\n",
        "The functional API can be used to build models that have multiple inputs. Typically,\n",
        "such models at some point merge their different input branches using a layer that can\n",
        "combine several tensors: by adding them, concatenating them, and so on. This is usually\n",
        "done via a Keras merge operation such as keras.layers.add, keras.layers\n",
        ".concatenate, and so on. Let’s look at a very simple example of a multi-input model:\n",
        "a question-answering model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlmvGcMcsRiU",
        "colab_type": "text"
      },
      "source": [
        "## Functional api implementation of 2-input question-answering model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBmqFR2lTqGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "bb9446b3-5881-4684-af13-0e561e991b02"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Embedding, concatenate, Dense, LSTM\n",
        "from keras import Input\n",
        "\n",
        "text_vocabulary_size=10_000\n",
        "question_vocabulary_size=10_000\n",
        "answer_vocabulary_size=500\n",
        "\n",
        "text_input=Input(shape=(None,), dtype='int32', name='text')\n",
        "embedded_text=Embedding(64, text_vocabulary_size)(text_input)\n",
        "encoded_text=LSTM(32)(embedded_text)\n",
        "\n",
        "question_input=Input(shape=(None,), dtype='int32', name='question')\n",
        "embedded_question=Embedding(32, question_vocabulary_size)(question_input)\n",
        "encoded_question=LSTM(16)(embedded_question)\n",
        "\n",
        "concatenated=concatenate([encoded_text, encoded_question], axis=-1)\n",
        "answer=Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
        "\n",
        "model=Model([text_input, question_input], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10000)  640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           1284224     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 16)           641088      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 48)           0           lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 500)          24500       concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,909,812\n",
            "Trainable params: 2,909,812\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5jOz-8x0PYe",
        "colab_type": "text"
      },
      "source": [
        "## Training a multi-input model\n",
        "\n",
        "Now, how do you train this two-input model? There are two possible APIs: you can feed\n",
        "the model a list of Numpy arrays as inputs, or you can feed it a dictionary that maps\n",
        "input names to Numpy arrays. Naturally, the latter option is available only if you give\n",
        "names to your inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiRhHTvhTqQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "5e5ab402-0d8f-4511-ba00-fd7c07cd21dd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples=1000\n",
        "max_length=100\n",
        "\n",
        "text=np.random.randint(low=1, high=text_vocabulary_size, size=(num_samples, max_length))\n",
        "question=np.random.randint(low=1, high=question_vocabulary_size, size=(num_samples, max_length))\n",
        "answers=np.random.randint(low=1, high=2, size=(num_samples, answer_vocabulary_size))\n",
        "\n",
        "model.fit([text,question], answers, epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3107.3741 - acc: 0.0570\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3115.3177 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3125.7460 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3131.0147 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3134.5017 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3137.2879 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3139.5625 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3141.4300 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3142.9723 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3144.2548 - acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0e760b7b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qkvjYFlTqXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# another way to fit model if inputs are named"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN2vWlDfTsuj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "13c2e3e9-94cf-429f-af0a-00af266839fc"
      },
      "source": [
        "model.fit({'text':text, 'question':question}, answers, epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3145.3249 - acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3146.2219 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3146.9768 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3147.6137 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3148.1528 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3148.6097 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3148.9978 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3149.3280 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3149.6098 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 3149.8507 - acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0e60f5ccf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Weo7b14sTs0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBM4u4qWBjnQ",
        "colab_type": "text"
      },
      "source": [
        "# Multi output models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iWHVXnVTs74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "76251180-98f0-442c-ccdb-0f068f708cdd"
      },
      "source": [
        "# functional ap implementation of a multi-output model\n",
        "# input is sequence of social media posts.\n",
        "# 3 outputs are-> age, gender and income group of person doingthe post\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv1D, Embedding, LSTM, MaxPooling1D, GlobalMaxPooling1D, Dense\n",
        "from keras import Input\n",
        "\n",
        "vocabulary_size=50_000\n",
        "num_income_groups=10\n",
        "\n",
        "posts_input=Input(shape=(None,), dtype='int32', name='posts')\n",
        "embedded_posts=Embedding(256, vocabulary_size)(posts_input)\n",
        "\n",
        "x=Conv1D(128, 5, activation='relu')(embedded_posts)\n",
        "x=MaxPooling1D(5)(x)\n",
        "x=Conv1D(256, 5, activation='relu')(x)\n",
        "x=Conv1D(256, 5, activation='relu')(x)\n",
        "x=MaxPooling1D(5)(x)\n",
        "x=Conv1D(256, 5, activation='relu')(x)\n",
        "x=Conv1D(256, 5, activation='relu')(x)\n",
        "x=GlobalMaxPooling1D()(x)\n",
        "x=Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "age_prediction=Dense(1, name='age')(x)\n",
        "gender_prediction=Dense(1, activation='sigmoid', name='gender')(x)\n",
        "income_prediction=Dense(10, activation='softmax', name='income')(x)\n",
        "\n",
        "model=Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "posts (InputLayer)              (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, None, 50000)  12800000    posts[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, None, 128)    32000128    embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, None, 128)    0           conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, None, 256)    164096      max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, None, 256)    327936      conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, None, 256)    0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, None, 256)    327936      max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, None, 256)    327936      conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 256)          0           conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          32896       global_max_pooling1d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "age (Dense)                     (None, 1)            129         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "income (Dense)                  (None, 10)           1290        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gender (Dense)                  (None, 1)            129         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 45,982,476\n",
            "Trainable params: 45,982,476\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSNYBlTHTtEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "                loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
        "model.compile(optimizer='rmsprop',\n",
        "                loss={'age': 'mse',\n",
        "                'income': 'categorical_crossentropy',\n",
        "                'gender': 'binary_crossentropy'})\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "    loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
        "    loss_weights=[0.25, 1., 10.])\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "    loss={'age': 'mse',\n",
        "    'income': 'categorical_crossentropy',\n",
        "    'gender': 'binary_crossentropy'},\n",
        "    loss_weights={'age': 0.25,\n",
        "    'income': 1.,\n",
        "    'gender': 10.})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3cQqZcXTtO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "30cc08d5-3b91-42c2-95e7-0cf9d448ec27"
      },
      "source": [
        "## training the model for multi-output\n",
        "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
        "epochs=10, batch_size=64)\n",
        "model.fit(posts, {'age': age_targets,\n",
        "            'income': income_targets,\n",
        "            'gender': gender_targets},\n",
        "            epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-63c6a5527924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## training the model for multi-output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(posts, [age_targets, income_targets, gender_targets],\n\u001b[0m\u001b[1;32m      3\u001b[0m epochs=10, batch_size=64)\n\u001b[1;32m      4\u001b[0m model.fit(posts, {'age': age_targets,\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'income'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mincome_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'posts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FjFE2jCRJhI",
        "colab_type": "text"
      },
      "source": [
        "# Directed acyclic graph of layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja3-fRVURKSB",
        "colab_type": "text"
      },
      "source": [
        "## INCEPTION\n",
        "It consists of a stack of modules\n",
        "that themselves look like small independent networks, split into several parallel\n",
        "branches.\n",
        "\n",
        "The most basic form of an Inception module has three to four branches\n",
        "starting with a 1 × 1 convolution, followed by a 3 × 3 convolution, and ending with the\n",
        "concatenation of the resulting features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI1dIbAqTtYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "fe87c2ef-2011-46d7-c7a6-c0311b3c0b07"
      },
      "source": [
        "from keras.datasets import iris\n",
        "from keras.layers import Conv2D, Dense, concatenate, Input, AvgPool2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "# imaginary_input\n",
        "(x_train, y_train), (x_val, y_val)=mnist.load_data()\n",
        "x_train.shape\n",
        "\n",
        "x_train[0]\n",
        "\n",
        "x=Input(shape=(None,None,256), dtype=\"float32\", name='input1')\n",
        "\n",
        "branch_a=Conv2D(filters=128, kernel_size=1, strides=2, activation=\"relu\")(x)\n",
        "\n",
        "branch_b=Conv2D(filters=128, kernel_size=128)(x)\n",
        "branch_b=Conv2D(filters=128, kernel_size=3, strides=2, activation='relu')(branch_b)\n",
        "\n",
        "branch_c=AvgPool2D(pool_size=(3,3), strides=2)(x)\n",
        "branch_c=Conv2D(filters=128, kernel_size=3, activation='relu')(branch_c)\n",
        "\n",
        "branch_d=Conv2D(filters=128, kernel_size=1, activation='relu')(x)\n",
        "branch_d=Conv2D(filters=128, kernel_size=3, activation='relu')(branch_d)\n",
        "branch_d=Conv2D(filters=128, kernel_size=3, activation='relu', strides=2)(branch_d)\n",
        "\n",
        "output=concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)\n",
        "\n",
        "output\n",
        "\n",
        "model=Model(x, output)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             (None, None, None, 2 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 1 32896       input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 1 536871040   input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 1 147584      conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 1 32896       input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 1 147584      conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 1 295040      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 1 147584      conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, None, None, 5 0           conv2d_16[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 537,674,624\n",
            "Trainable params: 537,674,624\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnTliiBQJoaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eabe16d-3e4c-4ad4-a992-fd998fe11cda"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Conv2D, Dense, concatenate, Input, AvgPool2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "# imaginary_input\n",
        "(x_train, y_train), (x_val, y_val)=mnist.load_data()\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp_d_gdCAX0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "incp=InceptionV3()\n",
        "incp.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74eotWmrJITz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incp.compile(optimizer='rmsprop', loss='mse', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGupmFBtAOcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "9e7d91de-ce13-41a6-b49d-8ad1cef0bca5"
      },
      "source": [
        "incp.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4951c55c6dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mincp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have 4 dimensions, but got array with shape (60000, 28, 28)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyG9IpHETtiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au70h7gNUN6G",
        "colab_type": "text"
      },
      "source": [
        "# Residual connection\n",
        "\n",
        "A residual connection consists of making the output of an earlier layer available as\n",
        "input to a later layer, effectively creating a shortcut in a sequential network. Rather\n",
        "than being concatenated to the later activation, the earlier output is summed with the\n",
        "later activation, which assumes that both activations are the same size. If they’re different\n",
        "sizes, you can use a linear transformation to reshape the earlier activation into the\n",
        "target shape (for example, a Dense layer without an activation or, for convolutional\n",
        "feature maps, a 1 × 1 convolution without an activation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZXSE1g_TtWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "4ce92875-4f4c-4f72-adce-8dfec5e9eb36"
      },
      "source": [
        "\"\"\"\n",
        "Here’s how to implement a residual connection in Keras when the feature-map\n",
        "sizes are the same, using identity residual connections. This example assumes the existence\n",
        "of a 4D input tensor x:\n",
        "\"\"\"\n",
        "from keras import layers\n",
        "\n",
        "x=Input(shape=(None,None,128), dtype=\"float32\", name='input1')\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "y = layers.add([y, x])\n",
        "model=Model(x,y)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             (None, None, None, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, None, None, 1 147584      input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, None, None, 1 147584      conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, None, None, 1 147584      conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 1 0           conv2d_222[0][0]                 \n",
            "                                                                 input1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 442,752\n",
            "Trainable params: 442,752\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d35BNSYzTtT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a5981419-1886-493a-88aa-86f4ba84822c"
      },
      "source": [
        "\"\"\"\n",
        "And the following implements a residual connection when the feature-map sizes differ,\n",
        "using a linear residual connection\n",
        "\"\"\"\n",
        "x=Input(shape=(None,None,256), dtype=\"float32\", name='input1')\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
        "y = layers.MaxPooling2D(2, strides=2)(y)\n",
        "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
        "y = layers.add([y, residual])\n",
        "\n",
        "model=Model(x,y)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             (None, None, None, 2 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, None, None, 1 295040      input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, None, None, 1 147584      conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, None, None, 1 0           conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, None, None, 1 32896       input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 1 0           max_pooling2d_11[0][0]           \n",
            "                                                                 conv2d_231[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 475,520\n",
            "Trainable params: 475,520\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWUKvEIPWuUS",
        "colab_type": "text"
      },
      "source": [
        "## Vanishing gradients in deep learning\n",
        "Backpropagation, the master algorithm used to train deep neural networks, works by\n",
        "propagating a feedback signal from the output loss down to earlier layers. If this feedback\n",
        "signal has to be propagated through a deep stack of layers, the signal may\n",
        "become tenuous or even be lost entirely, rendering the network untrainable. This\n",
        "issue is known as vanishing gradients.\n",
        "This problem occurs both with deep networks and with recurrent networks over very\n",
        "long sequences—in both cases, a feedback signal must be propagated through a\n",
        "long series of operations. You’re already familiar with the solution that the LSTM layer\n",
        "uses to address this problem in recurrent networks: it introduces a carry track that\n",
        "propagates information parallel to the main processing track. Residual connections\n",
        "work in a similar way in feedforward deep networks, but they’re even simpler: they\n",
        "introduce a purely linear information carry track parallel to the main layer stack, thus\n",
        "helping to propagate gradients through arbitrarily deep stacks of layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6m5fZ-fTtMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1mfv7pbig4Y",
        "colab_type": "text"
      },
      "source": [
        "## Layer weight sharing\n",
        "One more important feature of the functional API is the ability to reuse a layer\n",
        "instance several times. When you call a layer instance twice, instead of instantiating a\n",
        "new layer for each call, you reuse the same weights with every call. This allows you to\n",
        "build models that have shared branches—several branches that all share the same\n",
        "knowledge and perform the same operations. That is, they share the same representations\n",
        "and learn these representations simultaneously for different sets of inputs.\n",
        "For example, consider a model that attempts to assess the semantic similarity\n",
        "between two sentences. The model has two inputs (the two sentences to compare)\n",
        "and outputs a score between 0 and 1, where 0 means unrelated sentences and 1 means\n",
        "sentences that are either identical or reformulations of each other. Such a model\n",
        "could be useful in many applications, including deduplicating natural-language queries\n",
        "in a dialog system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAqIRAP2TtKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "\n",
        "lstm = layers.LSTM(32)\n",
        "left_input = Input(shape=(None, 128))\n",
        "left_output = lstm(left_input)\n",
        "right_input = Input(shape=(None, 128))\n",
        "right_output = lstm(right_input)\n",
        "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
        "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
        "model = Model([left_input, right_input], predictions)\n",
        "model.fit([left_data, right_data], targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuCUkYVPTtJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN9yTRWEjlNy",
        "colab_type": "text"
      },
      "source": [
        "## Models as layers\n",
        "Importantly, in the functional API, models can be used as you’d use layers—effectively,\n",
        "you can think of a model as a “bigger layer.” This is true of both the Sequential and\n",
        "Model classes. This means you can call a model on an input tensor and retrieve an output\n",
        "tensor:\n",
        "y = model(x)\n",
        "If the model has multiple input tensors and multiple output tensors, it should be\n",
        "called with a list of tensors:\n",
        "y1, y2 = model([x1, x2])\n",
        "When you call a model instance, you’re reusing the weights of the model—exactly like\n",
        "what happens when you call a layer instance. Calling an instance, whether it’s a layer\n",
        "instance or a model instance, will always reuse the existing learned representations of\n",
        "the instance—which is intuitive.\n",
        "One simple practical example of what you can build by reusing a model instance is\n",
        "a vision model that uses a dual camera as its input: two parallel cameras, a few centimeters\n",
        "(one inch) apart. Such a model can perceive depth, which can be useful in\n",
        "many applications. You shouldn’t need two independent models to extract visual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqyN6R6GTtB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51d8e09a-f01c-4577-d7c1-8438b9e1e89e"
      },
      "source": [
        "from keras import layers\n",
        "from keras import applications\n",
        "from keras import Input\n",
        "\n",
        "xception_base = applications.Xception(weights=None,\n",
        "include_top=False)\n",
        "left_input = Input(shape=(250, 250, 3))\n",
        "right_input = Input(shape=(250, 250, 3))\n",
        "left_features = xception_base(left_input)\n",
        "right_input = xception_base(right_input)\n",
        "merged_features = layers.concatenate([left_features, right_input], axis=-1)\n",
        "merged_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 8, 8, 4096])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PmCp1T2NgUu",
        "colab_type": "text"
      },
      "source": [
        "# Keras callbacks and TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A05hs_2N09i",
        "colab_type": "text"
      },
      "source": [
        "## Using callbacks to act on a model during training\n",
        "\n",
        "A\n",
        "callback is an object (a class instance implementing specific methods) that is passed to\n",
        "the model in the call to fit and that is called by the model at various points during\n",
        "training. It has access to all the available data about the state of the model and its performance,\n",
        "and it can take action: interrupt training, save a model, load a different\n",
        "weight set, or otherwise alter the state of the model.\n",
        "\n",
        "Here are some examples of ways you can use callbacks:\n",
        " Model checkpointing—Saving the current weights of the model at different points\n",
        "during training.\n",
        " Early stopping—Interrupting training when the validation loss is no longer\n",
        "improving (and of course, saving the best model obtained during training).\n",
        " Dynamically adjusting the value of certain parameters during training—Such as the\n",
        "learning rate of the optimizer.\n",
        " Logging training and validation metrics during training, or visualizing the representations\n",
        "learned by the model as they’re updated—The Keras progress bar that you’re\n",
        "familiar with is a callback!\n",
        "\n",
        "The keras.callbacks module includes a number of built-in callbacks (this is not an\n",
        "exhaustive list):\n",
        "keras.callbacks.ModelCheckpoint\n",
        "keras.callbacks.EarlyStopping\n",
        "keras.callbacks.LearningRateScheduler\n",
        "keras.callbacks.ReduceLROnPlateau\n",
        "keras.callbacks.CSVLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSYtwbjGjARj",
        "colab_type": "text"
      },
      "source": [
        "### THE MODELCHECKPOINT AND EARLYSTOPPING CALLBACKS\n",
        "You can use the EarlyStopping callback to interrupt training once a target metric\n",
        "being monitored has stopped improving for a fixed number of epochs. For instance,\n",
        "this callback allows you to interrupt training as soon as you start overfitting, thus\n",
        "avoiding having to retrain your model for a smaller number of epochs. This callback is\n",
        "typically used in combination with ModelCheckpoint, which lets you continually save\n",
        "the model during training (and, optionally, save only the current best model so far:\n",
        "the version of the model that achieved the best performance at the end of an epoch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN0E5KvDTtAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "callbacks_list=[\n",
        "                EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True),\n",
        "                ModelCheckpoint(filepath='savedModel.h5', monitor='val_loss', save_best_only=\"True\")\n",
        "]\n",
        "\n",
        "model.compile(optimizer='rmsprop', metrics=['acc'], loss='binary_cfossentropy')\n",
        "\n",
        "model.fit(x, y,\n",
        "        epochs=10,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks_list,\n",
        "        validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmZ3OXJIjMD3",
        "colab_type": "text"
      },
      "source": [
        "### THE REDUCELRONPLATEAU CALLBACK\n",
        "You can use this callback to reduce the learning rate when the validation loss has\n",
        "stopped improving. Reducing or increasing the learning rate in case of a loss plateau is\n",
        "is an effective strategy to get out of local minima during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKgRVWkOjJ4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks_list = [\n",
        "                    keras.callbacks.ReduceLROnPlateau(\n",
        "                    monitor='val_loss'\n",
        "                    factor=0.1,\n",
        "                    patience=10,\n",
        "                    )\n",
        "]\n",
        "model.fit(x, y,\n",
        "        epochs=10,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks_list,\n",
        "        validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loi_y19dl3b2",
        "colab_type": "text"
      },
      "source": [
        "### WRITING YOUR OWN CALLBACK\n",
        "If you need to take a specific action during training that isn’t covered by one of the\n",
        "built-in callbacks, you can write your own callback. Callbacks are implemented by subclassing\n",
        "the class keras.callbacks.Callback. You can then implement any number\n",
        "of the following transparently named methods, which are called at various points\n",
        "during training:\n",
        "on_epoch_begin\n",
        "on_epoch_end\n",
        "on_batch_begin\n",
        "on_batch_end\n",
        "on_train_begin\n",
        "on_train_end\n",
        "These methods all are called with a logs argument, which is a dictionary containing\n",
        "information about the previous batch, epoch, or training run: training and validation\n",
        "metrics, and so on. Additionally, the callback has access to the following attributes:\n",
        " self.model—The model instance from which the callback is being called\n",
        " self.validation_data—The value of what was passed to fit as validation data\n",
        "Here’s a simple example of a custom callback that saves to disk (as Numpy arrays) the\n",
        "activations of every layer of the model at the end of every epoch, computed on the\n",
        "first sample of the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il7oObluTs5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "class ActivationLogger(keras.callbacks.Callback):\n",
        "    def set_model(self, model):\n",
        "        self.model = model\n",
        "        layer_outputs = [layer.output for layer in model.layers]\n",
        "        self.activations_model = keras.models.Model(model.input, layer_outputs)\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if self.validation_data is None:\n",
        "            raise RuntimeError('Requires validation_data.')\n",
        "        validation_sample = self.validation_data[0][0:1]\n",
        "        activations = self.activations_model.predict(validation_sample)\n",
        "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w')\n",
        "        np.savez(f, activations)\n",
        "        f.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hzG1lhsm504",
        "colab_type": "text"
      },
      "source": [
        "# TensorBoard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no1NGO1lTs4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "abb8c4db-5fc6-45ee-b381-2215606f2fb1"
      },
      "source": [
        "# text classification on imdb 2000 max features and first 200 words\n",
        "\n",
        "from keras.layers import Embedding, Conv1D, Dense, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import imdb\n",
        "\n",
        "max_features=2000\n",
        "max_len=500\n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = imdb.load_data(num_words=max_features)\n",
        "x_train=sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_val=sequence.pad_sequences(x_val, maxlen=max_len)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=max_features, output_dim=128))\n",
        "model.add(Conv1D(filters=32, kernel_size=7, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=5))\n",
        "model.add(Conv1D(filters=32, kernel_size=7, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(units=1))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         256000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, None, 32)          28704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, None, 32)          7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 291,937\n",
            "Trainable params: 291,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-v0ORLOTszC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a directory for TensorBoard log files\n",
        "! mkdir my_tensorboard_log_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNdHG6cTrriy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "61722b4e-1964-4d3d-e1cb-2bb4626802c0"
      },
      "source": [
        "# Creating a directory for TensorBoard log files\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "callbacks=[\n",
        "           TensorBoard(log_dir=\"my_tensorboard_log_dir\", histogram_freq=1, embeddings_freq=1, update_freq='epoch')\n",
        "]\n",
        "\n",
        "history=model.fit(x=x_train, y=y_train, batch_size=128, epochs=10, callbacks=callbacks, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v2.py:102: UserWarning: The TensorBoard callback does not support embeddings display when using TensorFlow 2.0. Embeddings-related arguments are ignored.\n",
            "  warnings.warn('The TensorBoard callback does not support '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 8s 395us/step - loss: 0.6181 - acc: 0.6586 - val_loss: 0.4473 - val_acc: 0.8210\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 1s 73us/step - loss: 0.4591 - acc: 0.8033 - val_loss: 0.4181 - val_acc: 0.8320\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 1s 73us/step - loss: 0.3590 - acc: 0.8192 - val_loss: 1.1439 - val_acc: 0.5522\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 1s 73us/step - loss: 0.3354 - acc: 0.7782 - val_loss: 1.0679 - val_acc: 0.5594\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 1s 73us/step - loss: 0.2878 - acc: 0.7385 - val_loss: 0.5171 - val_acc: 0.7062\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 1s 73us/step - loss: 0.2498 - acc: 0.6813 - val_loss: 0.7050 - val_acc: 0.5688\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 1s 74us/step - loss: 0.2080 - acc: 0.6140 - val_loss: 0.6977 - val_acc: 0.5594\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 1s 73us/step - loss: 0.1669 - acc: 0.5594 - val_loss: 0.7608 - val_acc: 0.4766\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 1s 73us/step - loss: 0.1443 - acc: 0.4876 - val_loss: 0.8718 - val_acc: 0.4142\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 1s 72us/step - loss: 0.1155 - acc: 0.4262 - val_loss: 1.5194 - val_acc: 0.3210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJwmwGVVs72Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "9b424c35-0a81-4a56-df22-8bd4a6e95ed7"
      },
      "source": [
        "# launching tensorboard server\n",
        "!tensorboard --logdir=my_tensorboard_log_dir --bind_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-27 01:19:11.929438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 5, in <module>\n",
            "    from tensorboard.main import run_main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 43, in <module>\n",
            "    from tensorboard import default\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/default.py\", line 40, in <module>\n",
            "    from tensorboard.plugins.beholder import beholder_plugin_loader\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/beholder/__init__.py\", line 18, in <module>\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\", line 84, in <module>\n",
            "    from tensorflow.python import keras\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/__init__.py\", line 27, in <module>\n",
            "    from tensorflow.python.keras import models\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\", line 26, in <module>\n",
            "    from tensorflow.python.keras.engine import network\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\", line 44, in <module>\n",
            "    from tensorflow.python.keras.engine import input_layer as input_layer_module\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 25, in <module>\n",
            "    from tensorflow.python.keras.distribute import distributed_training_utils\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\", line 38, in <module>\n",
            "    from tensorflow.python.keras import callbacks\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 62, in <module>\n",
            "    import requests\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/__init__.py\", line 44, in <module>\n",
            "    import chardet\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 152, in __exit__\n",
            "  File \"<frozen importlib._bootstrap>\", line 104, in release\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}